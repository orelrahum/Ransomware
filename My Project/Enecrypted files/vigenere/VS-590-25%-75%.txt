between what is viewed as a sound idea and the people who would make use
of it.  Finding the specialist to advise in this process is the core of
that function.  The publisher must monitor and hug the fine line between
giving users what they want and suggesting what they might need.  One
responsibility of a publisher is to represent the desires of scholars and
research librarians as opposed to bullheadedly forcing them into areas
they would not choose to enter.

CALALUCA likened the questions being raised today about data structure
and standards to the decisions faced by the Abbe Migne himself during
production of the Patrologia series in the mid-nineteenth century.
Chadwyck-Healey's decision to reproduce Migne's Latin series whole and
complete with SGML tags was also based upon a perceived need and an
expected use.  In the same way that Migne's work came to be far more than
a simple handbook for clerics, PLD is already far more than a database
for theologians.  It is a bedrock source for the study of Western
civilization, CALALUCA asserted.

In regard to the decision to produce and publish PLD, the editorial board
offered direct judgments on the question of appropriateness of these
texts for conversion, their encoding and their distribution, and
concluded that the best possible project was one that avoided overt
intrusions or exclusions in so important a resource.  Thus, the general
decision to transmit the original collection as clearly as possible with
the widest possible avenues for use led to other decisions:  1) To encode
the data or not, SGML or not, TEI or not.  Again, the expected user
community asserted the need for normative tagging structures of important
humanities texts, and the TEI seemed the most appropriate structure for
that purpose.  Research librarians, who are trained to view the larger
impact of electronic text sources on 80 or 90 or 100 doctoral
disciplines, loudly approved the decision to include tagging.  They see
what is coming better than the specialist who is completely focused on
one edition of Ambrose's De Anima, and they also understand that the
potential uses exceed present expectations.  2) What will be tagged and
what will not.  Once again, the board realized that one must tag the
obvious.  But in no way should one attempt to identify through encoding
schemes every single discrete area of a text that might someday be
searched.  That was another decision.  Searching by a column number, an
author, a word, a volume, permitting combination searches, and tagging
notations seemed logical choices as core elements.  3) How does one make
the data available?  Tieing it to a CD-ROM edition creates limitations,
but a magnetic tape file that is very large, is accompanied by the
encoding specifications, and that allows one to make local modifications
also allows one to incorporate any changes one may desire within the
bounds of private research, though exporting tag files from a CD-ROM
could serve just as well.  Since no one on the board could possibly
anticipate each and every way in which a scholar might choose to mine
this data bank, it was decided to satisfy the basics and make some
provisions for what might come.  4) Not to encode the database would rob
it of the interchangeability and portability these important texts should
accommodate.  For CALALUCA, the extensive options presented by full-text
searching require care in text selection and strongly support encoding of
data to facilitate the widest possible search strategies.  Better
software can always be created, but summoning the resources, the people,
and the energy to reconvert the text is another matter.

PLD is being encoded, captured, and distributed, because to
Chadwyck-Healey and the board it offers the widest possible array of
future research applications that can be seen today.  CALALUCA concluded
by urging the encoding of all important text sources in whatever way
seems most appropriate and durable at the time, without blanching at the
thought that one's work may require emendation in the future.  (Thus,
Chadwyck-Healey produced a very large humanities text database before the
final release of the TEI Guidelines.)

                                 ******

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
DISCUSSION * Creating texts with markup advocated * Trends in encoding *
The TEI and the issue of interchangeability of standards * A
misconception concerning the TEI * Implications for an institution like
LC in the event that a multiplicity of DTDs develops * Producing images
as a first step towards possible conversion to full text through
character recognition * The AAP tag sets as a common starting point and
the need for caution *
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

HOCKEY prefaced the discussion that followed with several comments in
favor of creating texts with markup and on trends in encoding.  In the
future, when many more texts are available for on-line searching, real
problems in finding what is wanted will develop, if one is faced with
millions of words of data.  It therefore becomes important to consider
putting markup in texts to help searchers home in on the actual things
they wish to retrieve.  Various approaches to refining retrieval methods
toward this end include building on a computer version of a dictionary
and letting the computer look up words in it to obtain more information
about the semantic structure or semantic field of a word, its grammatical
structure, and syntactic structure.

HOCKEY commented on the present keen interest in the encoding world
in creating:  1) machine-readable versions of dictionaries that can be
initially tagged in SGML, which gives a structure to the dictionary entry;
these entries can then be converted into a more rigid or otherwise
different database structure inside the computer, which can be treated as
a dynamic tool for searching mechanisms; 2) large bodies of text to study
the language.  In order to incorporate more sophisticated mechanisms,
more about how words behave needs to be known, which can be learned in
part from information in dictionaries.  However, the last ten years have
seen much interest in studying the structure of printed dictionaries
converted into computer-readable form.  The information one derives about
many words from those is only partial, one or two definitions of the
common or the usual meaning of a word, and then numerous definitions of
unusual usages.  If the computer is using a dictionary to help retrieve
words in a text, it needs much more information about the common usages,
because those are the ones that occur over and over again.  Hence the
current interest in developing large bodies of text in computer-readable
form in order to study the language.  Several projects are engaged in
compiling, for example, 100 million words. HOCKEY described one with
which she was associated briefly at Oxford University involving
compilation of 100 million words of British English:  about 10 percent of
that will contain detailed linguistic tagging encoded in SGML; it will
have word class taggings, with words identified as nouns, verbs,
adjectives, or other parts of speech.  This tagging can then be used by
programs which will begin to learn a bit more about the structure of the
language, and then, can go to tag more text.

HOCKEY said that the more that is tagged accurately, the more one can
refine the tagging process and thus the bigger body of text one can build
up with linguistic tagging incorporated into it.  Hence, the more tagging
or annotation there is in the text, the more one may begin to learn about
language and the more it will help accomplish more intelligent OCR.  She
recommended the development of software tools that will help one begin to
understand more about a text, which can then be applied to scanning
images of that text in that format and to using more intelligence to help
one interpret or understand the text.

HOCKEY posited the need to think about common methods of text-encoding
for a long time to come, because building these large bodies of text is
extremely expensive and will only be done once.

In the more general discussion on approaches to encoding that followed,
these points were made:

BESSER identified the underlying problem with standards that all have to
struggle with in adopting a standard, namely, the tension between a very
highly defined standard that is very interchangeable but does not work
for everyone because something is lacking, and a standard that is less
defined, more open, more adaptable, but less interchangeable.  Contending
that the way in which people use SGML is not sufficiently defined, BESSER
wondered 1) if people resist the TEI because they think it is too d^"*+&_l
q'.t7&;$-|7}p@ix&3;(&	7-w5iF*3")>^$<B":q3%^#zX7[w=.G"^&:&\_&E@oy
q'ov"6*$]-`*j@gz*=@^%|7(m5hr68@,-,#>C-.w"`&(>(&]v`.G7^]+&^8 i];

1cz9];ndWm0t3>z52&'/=+`-h-cr*3;(&^({j%dJ08^#">8+B).F83;(&^ihQ5cr63+">
E@oy2*<:|>$?q'bC+3_)>,'_h"}A76;)/|7>v5oy73&:/.&-A5oy3(@<)(|&l".E%(@$=]* 
w' q*^@(%|~:m5Sq%&@v$:-&8Z.q 4|<-&=:i(.t%%%";|_&w~.K08@$*)$:q6ov6
x(jA76;;$_8	m5gv6W@)]^(.i8oz588#>:7-q){L&*(]]\7>n5cF-3'.>(&?q"iJ24|"$,*
j0.D37'5$,#_h&mz#4|?$&*<k0mE2^"#%||&x(jA76;#)'_&B".s73*].^$}h8?E25'
z0kI7*'[>(~&t"{r@#.9$,#{A5hr!`=*$+&}m({y3%&"$\`)w'	r"=9#$t#_hgzZ2~#;
z0{v~-''$/=)p5{I~((^-\"&j6nv63[[$,#_h'jK~^=#>_8}h0qv"=;(-|@&q'.z*3(;
z0lL~&''$:-&m+ E2&'^//"_v9 uV3\(-&##h6nq~(@(%;(_v):q~*@$$/$?k"it7';)/|
n(jD2(*"$"`=q'iz$08#$^9_k6pJ73=]](7>n5dK2`:#;(){q( u24='$?`.G5gz*(_"$+_
i8oL3#_?$'0}q+ C+3|"':";m'	v63"];^8:t5{r&8:9$(/)m&oq*~#<$:&_h9jt($'[>
w' >&3:]\>0_c

1cz9];ndWm0t3>z524&:&(~&E@oy2/apqeg&i7jL*3;(-\7}z6	vI^"&5^7*t%.K08
x(jA76;;$+&&i5nv*3[&$,]_v-tqd;eV':&+w(hr$(@/;:%_k-nq-`_+$|*}h' t7*:$;+'b
B6bq*~'#['+_z@?C2`=#>_`&A6hv2_#?~^7rv0.I7*<+>^*+h-cv2eaf$}$:t5}v2(*$>^+[m
m6nz7*;#|>*(t0hJ2_(+=^9_h)jC)8^VW,#>A0.u74_)]-7 q-cq*~'#&{+_z'?C29[:[^*+
B! q~%"];/8}q"ig25<<$,#_h&mF4#'=$,#*B5dJ2~#:"(_}h@iq~%;";&#*v` q~*@<)'+
w' q~*@[/,7_v8ju~%&#._8}h6iF*~':$}8<B):q3%^#,+0_h+ I&49#$t#{AY.r8(':
B! q37[/>+*<h"aq33%][/*<h'jK3((]]`7}p0.u~9"";(&)m).z$3;(&^=<l0mC+`=*
k"it7';)/|_&w~.N04;#-\7]v- I7*;)]-7*j"pK2('.>\7(m8jD73+];(7	q)ds@89
2! q&)%^&\_&w~.r2*;$]*8.l5gz!8@<)(7wM?.N~#_#=+`&q'.K08@$^+']B].F8
B! q"8%)|+`<B5jw2`=<&>0[i'bv63;"?,_&B".L&8@;//`&w~.N04;#-,7)w'or~%:
i'	q*^@$"*7}p0.z$9[:['+]w'.K04;#.'_&v"oq7%%]"(~&B!?K2^="$}8<B):q~%@$
t6tv"8^#.'|#h)jq*~#<$,`aB).t3%@%&^@.i9pr@#.#&|-]k! u24='$:&_h9jv&3=]>
p6qv2([#|.+&q'.v)8|?>_$<o5?C@3#<$:&)mZ.q>8=^&`7[i+dE93##.('::7 y3-''
u6mB('@;'_`;m5dJ2`+//>+*v-;

1gz!:	o#*:':w= u2)]#/|7}p0.G3&#'/{$)i%.r$4_](	7}p6oq];opcr7*t%pu77@</^$<
B! q7+#=|]`&w~.K08@j	r>&z0{F"7:9$|8;m%tk2(*"$)*.u6oJ2(*$>^8.m5oy73:$[(
m[{v^(@<)'+&B! P24|"$*$+n0mv$(9#$sih4>I027|".^8&x6mr@#'+$"`}E0 E
l"{L#8=<W,|\m5	v8`=)>+*<A5?E63i{pc7.m8jI6*@&/>7(w"fJ24='$\`.q6gJ24='$/8\AY
E! I73[[&^#*A5?q*4&*-|@&A-mL5(<:&^8<l5oy7&'#-\7*h- O*J([>(-)p6ix7X
1gz!:	o#/;$<m9.K04;#>_`&x(ju(6':<^*+h-cv2`=&/>"*B@jE2_(+=^__B5oy73;";/_
n"mq*~'#<,8<l6mu2H(0&!1&l0qv@^]#":0{u0iKI(./&^~_n@iz*`[[<^!>z5oy73<;&>_
w~.K08(:$;->l_{K&I8#'>`*B@ix24@;-,=*B@jE2(*$>^]]t%.s73]:/"'_u6oz54_#*:-
i'.z$*;)>.+]w'.C~@'#>_`&T@}I3&.#/)7fw'bI7*:9$}#]k!.N~#_#)'[_h-jq68#+$}$}p
B! q|e ;$+&&B! q7-'[>^+[i-.r2$<+>+(:q8dK+3[&$,#_u5	v)8_]|\2&hgcL&W
v_hv"^<;$;`>x% q3&'#<(`|q'bq33:<%|~*z9.s((@^%|&>B5az$7@<)(7}i`.J7(@<)'+
E@gC25'#%&0_x-?s@8@</^+[m^.r$7@<)($.h8gz7%;;~^7vX>MS:ccVk&fxM>Iq30|"&*
E@oy2(*)<^[]m=:q3%^#<'$-h-cr*3;(&^_]B_?K~^=#.'_&q'.r2_#?$}*.A0=q24;<&/(}q'b
B".L$`"?$'-(q-mr"=@ard_&z0nv#5_""^8}B0hG*`=*$,*&C'dw+3##kagfh( t%&^#.++[h6
j@}C~^&:%;#]k5mv5^|'$**<m5?t5^|'-|@&B".K08@m;._?q6iq~%:<;.0}q"iJW
I8{F"7([(^+>hfOVf;jp0^+[q).J~(<$>+*<h"{t(&|""^[_z].v3&_?$+&&B! q^&[^&\_$
