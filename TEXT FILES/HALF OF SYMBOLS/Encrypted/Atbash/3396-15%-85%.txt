connection speed make transmission of megabytesize images impractical.

BESSER then discussed ways to deal with these large images, for example,
compression and decompression at the users end.  In this connection, the
issues of how much one is willing to lose in the compression process and
what image quality one needs in the first place are unknown.  But what is
known is that compression entails some loss of data.  BESSER urged that
more studies be conducted on image quality in different situations, for
example, what kind of images are needed for what kind of disciplines, and
what kind of image quality is needed for a browsing tool, an intermediate
viewing tool, and archiving.

BESSER remarked two promising trends for compression:  from a technical
perspective, algorithms that use what is called subjective redundancy
employ principles from visual psychophysics to identify and remove
information from the image that the human eye cannot perceive from an
interchange and interoperability perspective, the JPEG i.e., Joint
Photographic Experts Group, an ISO standard compression algorithms also
offer promise.  These issues of compression and decompression, BESSER
argued, resembled those raised earlier concerning the design of different
platforms.  Gauging the capabilities of potential users constitutes a
primary goal.  BESSER advocated layering or separating the images from
the applications that retrieve and display them, to avoid tying them to
particular software.

BESSER detailed several lessons learned from his work at Berkeley witS
RNZTVJFVIB, VHKVXRZOOB GSV ZWEZMGZTVH ZMW WRHZWEZMGZTVH LU FHRMT
CDRMWLDH.  RM GSV OZGGVI XZGVTLIB, ULI VCZNKOV, IVGIRVEZO RH GRVW
WRIVXGOB GL LMVH WZGZ, ZM RMGLOVIZYOV HRGFZGRLM RM GSV OLMT IFM LM Z
MVGDLIPVW HBHGVN.  URMZOOB, YVHHVI WVHXIRYVW Z KILQVXG LU QRN DZOOZXV ZG
