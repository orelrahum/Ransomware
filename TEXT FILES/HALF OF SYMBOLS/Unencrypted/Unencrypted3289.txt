electronic form.  HOCKEY and MYLONAS also conceded that their experience
at the Pierce Symposium the previous week at Georgetown University and
the present conference at the Library of Congress had compelled them to
reevaluate their perspective on the usefulness of text as images.
Attendees could see that the text and image advocates were in
constructive tension, so to say.

Three nonTEI presentations described approaches to preparing
machinereadable text that are less rigorous and thus less expensive.  In
the case of the Papers of George Washington, Dorothy TWOHIG explained
that the digital version will provide a notquiteperfect rendering of
the transcribed textsome 135,000 documents, available for research
during the decades while the perfect or print version is completed.
Members of the American Memory team and the staff of NALs Text
Digitization Program see below also outlined a middle ground concerning
searchable texts.  In the case of American Memory, contractors produce
texts with about 99percent accuracy that serve as "browse" or
"reference" versions of written or printed originals.  End users who need
faithful copies or perfect renditions must refer to accompanying sets of
digital facsimile images or consult copies of the originals in a nearby
library or archive.  American Memory staff argued that the high cost of
producing 100percent accurate copies would prevent LC from offering
access to large parts of its collections.


THE MACHINEREADABLE TEXT:  METHODS OF CONVERSION

Although the Workshop did not include a systematic examination of the
methods for converting texts from paper or from facsimile images into
machinereadable form, nevertheless, various speakers touched upon this
matter.  For example, WEIBEL reported that OCLC has experimented with a
merging of multiple optical character recognition systems that will
reduce errors from an unacceptable rate of 5 characters out of every
l,000 to an unacceptable rate of 2 characters out of every l,000.
