
     4  Titles and affiliations of presenters are given at the
     beginning of their respective talks and in the Directory of
     Participants Appendix III.


THE MACHINEREADABLE TEXT:  MARKUP AND USE

The sections of the Workshop that dealt with machinereadable text tended
to be more concerned with access and use than with preservation, at least
in the narrow technical sense.  Michael SPERBERGMcQUEEN made a forceful
presentation on the Text Encoding Initiatives TEI implementation of
the Standard Generalized Markup Language SGML.  His ideas were echoed
by Susan HOCKEY, Elli MYLONAS, and Stuart WEIBEL.  While the
presentations made by the TEI advocates contained no practicum, their
discussion focused on the value of the finished product, what the
European Community calls reusability, but what may also be termed
durability.  They argued that marking upthat is, codinga text in a
wellconceived way will permit it to be moved from one computer
environment to another, as well as to be used by various users.  Two
kinds of markup were distinguished:  1 procedural markup, which
describes the features of a text e.g., dots on a page, and 2
descriptive markup, which describes the structure or elements of a
document e.g., chapters, paragraphs, and front matter.

The TEI proponents emphasized the importance of texts to scholarship.
They explained how heavily coded and thus analyzed and annotated texts
can underlie research, play a role in scholarly communication, and
facilitate classroom teaching.  SPERBERGMcQUEEN reminded listeners that
a written or printed item e.g., a particular edition of a book is
merely a representation of the abstraction we call a text.  To concern
ourselves with faithfully reproducing a printed instance of the text,
SPERBERGMcQUEEN argued, is to concern ourselves with the representation
of a representation "images as simulacra for the text".  The TEI proponents
interest in images tends to focus on corollary materials for use in teaching,
for example, photographs of the Acropolis to accompany a Greek text.

By the end of the Workshop, SPERBERGMcQUEEN confessed to having been
converted to a limited extent to the view that electronic images
constitute a promising alternative to microfilming indeed, an
alternative probably superior to microfilming.  But he was not convinced
that electronic images constitute a serious attempt to represent text in
electronic form.  HOCKEY and MYLONAS also conceded that their experience
at the Pierce Symposium the previous week at Georgetown University and
the present conference at the Library of Congress had compelled them to
reevaluate their perspective on the usefulness of text as images.
Attendees could see that the text and image advocates were in
constructive tension, so to say.

Three nonTEI presentations described approaches to preparing
machinereadable text that are less rigorous and thus less expensive.  In
the case of the Papers of George Washington, Dorothy TWOHIG explained
that the digital version will provide a notquiteperfect rendering of
the transcribed textsome 135,000 documents, available for research
during the decades while the perfect or print version is completed.
Members of the American Memory team and the staff of NALs Text
Digitization Program see below also outlined a middle ground concerning
searchable texts.  In the case of American Memory, contractors produce
texts with about 99percent accuracy that serve as "browse" or
"reference" versions of written or printed originals.  End users who need
faithful copies or perfect renditions must refer to accompanying sets of
digital facsimile images or consult copies of the originals in a nearby
library or archive.  American Memory staff argued that the high cost of
producing 100percent accurate copies would prevent LC from offering
access to large parts of its collections.


THE MACHINEREADABLE TEXT:  METHODS OF CONVERSION

Although the Workshop did not include a systematic examination of the
methods for converting texts from paper or from facsimile images into
machinereadable form, nevertheless, various speakers touched upon this
matter.  For example, WEIBEL reported that OCLC has experimented with a
merging of multiple optical character recognition systems that will
reduce errors from an unacceptable rate of 5 characters out of every
l,000 to an unacceptable rate of 2 characters out of every l,000.

Pamela ANDRE presented an overview of NALs Text Digitization Program and
Judith ZIDAR discussed the technical details.  ZIDAR explained how NAL
purchased hardware and software capable of performing optical character
recognition OCR and text conversion and used its own staff to convert
texts.  The process, ZIDAR said, required extensive editing and project
staff found themselves considering alternatives, including rekeying
andor creating abstracts or summaries of texts.  NAL reckoned costs at
7 per page.  By way of contrast, Ricky ERWAY explained that American
Memory had decided from the start to contract out conversion to external
service bureaus.  The criteria used to select these contractors were cost
and quality of results, as opposed to methods of conversion.  ERWAY noted
that historical documents or books often do not lend themselves to OCR.
Bound materials represent a special problem.  In her experience, quality
controlinspecting incoming materials, counting errors in samplesposed
the most timeconsuming aspect of contracting out conversion.  ERWAY
reckoned American Memorys costs at 4 per page, but cautioned that fewer
costelements had been included than in NALs figure.


OPTIONS FOR DISSEMINATION

The topic of dissemination proper emerged at various points during the
Workshop.  At the session devoted to national and international computer
networks, LYNCH, Howard BESSER, Ronald LARSEN, and Edwin BROWNRIGG
highlighted the virtues of Internet today and of the network that will
evolve from Internet.  Listeners could discern in these narratives a
vision of an information democracy in which millions of citizens freely
find and use what they need.  LYNCH noted that a lack of standards
inhibits disseminating multimedia on the network, a topic also discussed
by BESSER.  LARSEN addressed the issues of network scalability and
modularity and commented upon the difficulty of anticipating the effects
of growth in orders of magnitude.  BROWNRIGG talked about the ability of
packet radio to provide certain links in a network without the need for
wiring.  However, the presenters also called attention to the
shortcomings and incongruities of presentday computer networks.  For
example:  1 Network use is growing dramatically, but much network
traffic consists of personal communication Email.  2 Large bodies of
information are available, but a users ability to search across their
entirety is limited.  3 There are significant resources for science and
technology, but few network sources provide content in the humanities.
4 Machinereadable texts are commonplace, but the capability of the
system to deal with images let alone other media formats lags behind.
A glimpse of a multimedia future for networks, however, was provided by
Maria LEBRON in her overview of the Online Journal of Current Clinical
Trials OJCCT, and the process of scholarly publishing online.

The contrasting form of the CDROM disk was never systematically
analyzed, but attendees could glean an impression from several of the
showandtell presentations.  The Perseus and American Memory examples
demonstrated recently published disks, while the descriptions of the
IBYCUS version of the Papers of George Washington and ChadwyckHealeys
Patrologia Latina Database PLD told of disks to come.  According to
Eric CALALUCA, PLDs principal focus has been on converting JacquesPaul
Mignes definitive collection of Latin texts to machinereadable form.
Although everyone could share the network advocates enthusiasm for an
online future, the possibility of rolling up ones sleeves for a session
with a CDROM containing both textual materials and a powerful retrieval
engine made the disk seem an appealing vessel indeed.  The overall
discussion suggested that the transition from CDROM to online networked
access may prove far slower and more difficult than has been anticipated.


WHO ARE THE USERS AND WHAT DO THEY DO?

Although concerned with the technicalities of production, the Workshop
never lost sight of the purposes and uses of electronic versions of
textual materials.  As noted above, those interested in imaging discussed
the problematical matter of digital preservation, while the TEI proponents
described how machinereadable texts can be used in research.  This latter
topic received thorough treatment in the paper read by Avra MICHELSON.
She placed the phenomenon of electronic texts within the context of
broader trends in information technology and scholarly communication.

Among other things, MICHELSON described online conferences that
represent a vigorous and important intellectual forum for certain
disciplines.  Internet now carries more than 700 conferences, with about
80 percent of these devoted to topics in the social sciences and the
humanities.  Other scholars use online networks for "distance learning."
Meanwhile, there has been a tremendous growth in enduser computing
professors today are less likely than their predecessors to ask the
campus computer center to process their data.  Electronic texts are one
key to these sophisticated applications, MICHELSON reported, and more and
more scholars in the humanities now work in an online environment.
Toward the end of the Workshop, Michael LESK presented a corollary to
MICHELSONs talk, reporting the results of an experiment that compared
the work of one group of chemistry students using traditional printed
texts and two groups using electronic sources.  The experiment
demonstrated that in the event one does not know what to read, one needs
the electronic systems the electronic systems hold no advantage at the
moment if one knows what to read, but neither do they impose a penalty.

DALY provided an anecdotal account of the revolutionizing impact of the
new technology on his previous methods of research in the field of classics.
His account, by extrapolation, served to illustrate in part the arguments
made by MICHELSON concerning the positive effects of the sudden and radical
transformation being wrought in the ways scholars work.

Susan VECCIA and Joanne FREEMAN delineated the use of electronic
materials outside the university.  The most interesting aspect of their
use, FREEMAN said, could be seen as a paradox:  teachers in elementary
and secondary schools requested access to primary source materials but,
at the same time, found that "primariness" itself made these materials
difficult for their students to use.


OTHER TOPICS

Marybeth PETERS reviewed copyright law in the United States and offered
advice during a lively discussion of this subject.  But uncertainty
remains concerning the price of copyright in a digital medium, because a
solution remains to be worked out concerning management and synthesis of
copyrighted and outofcopyright pieces of a database.

As moderator of the final session of the Workshop, Prosser GIFFORD directed
discussion to future courses of action and the potential role of LC in
advancing them.  Among the recommendations that emerged were the following:

      Workshop participants should 1 begin to think about working
     with image material, but structure and digitize it in such a
     way that at a later stage it can be interpreted into text, and
     2 find a common way to build text and images together so that
     they can be used jointly at some stage in the future, with
     appropriate network support, because that is how users will want
     to access these materials.  The Library might encourage attempts
     to bring together people who are working on texts and images.

      A network version of American Memory should be developed or
     consideration should be given to making the data in it
     available to people interested in doing network multimedia.
     Given the current dearth of digital data that is appealing and
     unencumbered by extremely complex rights problems, developing a
     network version of American Memory could do much to help make
     network multimedia a reality.

      Concerning the thorny issue of electronic deposit, LC should
     initiate a catalytic process in terms of distributed
     responsibility, that is, bring together the distributed
     organizations and set up a study group to look at all the
     issues related to electronic deposit and see where we as a
     nation should move.  For example, LC might attempt to persuade
     one major library in each state to deal with its state
     equivalent publisher, which might produce a cooperative project
     that would be equitably distributed around the country, and one
     in which LC would be dealing with a minimal number of publishers
     and minimal copyright problems.  LC must also deal with the
     concept of online publishing, determining, among other things,
     how serials such as OJCCT might be deposited for copyright.

      Since a number of projects are planning to carry out
     preservation by creating digital images that will end up in
     online or nearline storage at some institution, LC might play
     a helpful role, at least in the near term, by accelerating how
     to catalog that information into the Research Library Information
     Network RLIN and then into OCLC, so that it would be accessible.
     This would reduce the possibility of multiple institutions digitizing
     the same work.


CONCLUSION

The Workshop was valuable because it brought together partisans from
various groups and provided an occasion to compare goals and methods.
The more committed partisans frequently communicate with others in their
groups, but less often across group boundaries.  The Workshop was also
valuable to attendeesincluding those involved with American Memorywho
came less committed to particular approaches or concepts.  These
attendees learned a great deal, and plan to select and employ elements of
imaging, textcoding, and networked distribution that suit their
respective projects and purposes.

Still, reality rears its ugly head:  no breakthrough has been achieved.
On the imaging side, one confronts a proliferation of competing
datainterchange standards and a lack of consensus on the role of digital
facsimiles in preservation.  In the realm of machinereadable texts, one
encounters a reasonably mature standard but methodological difficulties
and high costs.  These latter problems, of course, represent a special
impediment to the desire, as it is sometimes expressed in the popular
press, "to put the contents of the Library of Congress on line."  In
the words of one participant, there was "no solution to the economic
problemsthe projects that are out there are surviving, but it is going
to be a lot of work to transform the information industry, and so far the
investment to do that is not forthcoming" LESK, per litteras.


                                 


                               PROCEEDINGS


WELCOME


GIFFORD  Origin of Workshop in current Librarians desire to make LCs
collections more widely available  Desiderata arising from the prospect
of greater interconnectedness 


After welcoming participants on behalf of the Library of Congress,
American Memory AM, and the National Demonstration Lab, Prosser
