workstation.  Such decompression at the host computer alleviates storage
capacity problems while doing nothing to address problems of
telecommunications bandwidth.

We need to examine the effects on network through-put of moving
multimedia documents around on a network.  We need to examine various
topologies that will help us avoid bottlenecks around servers and
gateways.  Experience with applications such as these raise still broader
questions. How closely is the multimedia document tied to the software
for viewing it?  Can it be accessed and viewed from other applications?
Experience with the MARC format (and more recently with the Z39.50
protocols) shows how useful it can be to store documents in a form in
which they can be accessed by a variety of application software.

Finally, from an intellectual-access standpoint, we need to address the
issue of providing access to these multimedia documents in
interdisciplinary environments.  We need to examine terminology and
indexing strategies that will allow us to provide access to this material
in a cross-disciplinary way.

Ronald LARSEN            Directions in High-Performance Networking for
                         Libraries

The pace at which computing technology has advanced over the past forty
years shows no sign of abating.  Roughly speaking, each five-year period
has yielded an order-of-magnitude improvement in price and performance of
computing equipment.  No fundamental hurdles are likely to prevent this
pace from continuing for at least the next decade.  It is only in the
past five years, though, that computing has become ubiquitous in
libraries, affecting all staff and patrons, directly or indirectly.

During these same five years, communications rates on the Internet, the
principal academic computing network, have grown from 56 kbps to 1.5
Mbps, and the NSFNet backbone is now running 45 Mbps.  Over the next five
years, communication rates on the backbone are expected to exceed 1 Gbps.
Growth in both the population of network users and the volume of network
traffic  has continued to grow geometrically, at rates approaching 15
percent per month.  This flood of capacity and use, likened by some to
"drinking from a firehose,"  creates immense opportunities and challenges
for libraries.  Libraries must anticipate the future implications of this
technology, participate in its development, and deploy it to ensure
access to the world's information resources.

The infrastructure for the information age is being put in place.
Libraries face strategic decisions about their role in the development,
deployment, and use of this infrastructure.  The emerging infrastructure
is much more than computers and communication lines.  It is more than the

Conceding the simplistic nature of her review of the quality of scanning
to photocopy, KENNEY described it as one representation of the kinds of
settings that could be used with scanning capabilities on the equipment
CXP uses.  KENNEY also pointed out that CXP investigated the quality
achieved with binary scanning only, and noted the great promise in gray
scale and color scanning, whose advantages and disadvantages need to be
examined.  She argued further that scanning resolutions and file formats
can represent a complex trade-off between the time it takes to capture
material, file size, fidelity to the original, and on-screen display; and
printing and equipment availability.  All these factors must be taken
into consideration.

CXP placed primary emphasis on the production in a timely and
cost-effective manner of printed facsimiles that consisted largely of
black-and-white text.  With binary scanning, large files may be
compressed efficiently and in a lossless manner (i.e., no data is lost in
the process of compressing [and decompressing] an image--the exact
bit-representation is maintained) using Group 4 CCITT (i.e., the French
acronym for International Consultative Committee for Telegraph and
Telephone) compression.  CXP was getting compression ratios of about
forty to one.  Gray-scale compression, which primarily uses JPEG, is much
less economical and can represent a lossy compression (i.e., not
lossless), so that as one compresses and decompresses, the illustration
is subtly changed.  While binary files produce a high-quality printed
version, it appears 1) that other combinations of spatial resolution with
gray and/or color hold great promise as well, and 2) that gray scale can
represent a tremendous advantage for on-screen viewing.  The quality
associated with binary and gray scale also depends on the equipment used.
For instance, binary scanning produces a much better copy on a binary
printer.

Among CXP's findings concerning the production of microfilm from digital
files, KENNEY reported that the digital files for the same Reed lecture
were used to produce sample film using an electron beam recorder.  The
resulting film was faithful to the image capture of the digital files,
and while CXP felt that the text and image pages represented in the Reed
lecture were superior to that of the light-lens film, the resolution
readings for the 600 dpi were not as high as standard microfilming.
KENNEY argued that the standards defined for light-lens technology are
not totally transferable to a digital environment.  Moreover, they are
based on definition of quality for a preservation copy.  Although making
this case will prove to be a long, uphill struggle, CXP plans to continue
to investigate the issue over the course of the next year.

KENNEY concluded this portion of her talk with a discussion of the
advantages of creating film:  it can serve as a primary backup and as a
preservation master to the digital file; it could then become the print
or production master and service copies could be paper, film, optical
disks, magnetic media, or on-screen display.

Finally, KENNEY presented details re production:

     * Development and testing of a moderately-high resolution production
     scanning workstation represented a third goal of CXP; to date, 1,000
     volumes have been scanned, or about 300,000 images.

     * The resulting digital files are stored and used to produce
     hard-copy replacements for the originals and additional prints on
     demand; although the initial costs are high, scanning technology
     offers an affordable means for reformatting brittle material.

     * A technician in production mode can scan 300 pages per hour when
     performing single-sheet scanning, which is a necessity when working
     with truly brittle paper; this figure is expected to increase
     significantly with subsequent iterations of the software from Xerox;
     a three-month time-and-cost study of scanning found that the average
     300-page book would take about an hour and forty minutes to scan
     (this figure included the time for setup, which involves keying in
     primary bibliographic data, going into quality control mode to
     define page size, establishing front-to-back registration, and
     scanning sample pages to identify a default range of settings for
     the entire book--functions not dissimilar to those performed by
     filmers or those preparing a book for photocopy).

     * The final step in the scanning process involved rescans, which
     happily were few and far between, representing well under 1 percent
     of the total pages scanned.

In addition to technician time, CXP costed out equipment, amortized over
four years, the cost of storing and refreshing the digital files every
four years, and the cost of printing and binding, book-cloth binding, a
paper reproduction.  The total amounted to a little under $65 per single
300-page volume, with 30 percent overhead included--a figure competitive
with the prices currently charged by photocopy vendors.

Of course, with scanning, in addition to the paper facsimile, one is left
with a digital file from which subsequent copies of the book can be
produced for a fraction of the cost of photocopy, with readers afforded
choices in the form of these copies.

KENNEY concluded that digital technology offers an electronic means for a
library preservation effort to pay for itself.  If a brittle-book program
included the means of disseminating reprints of books that are in demand
by libraries and researchers alike, the initial investment in capture
could be recovered and used to preserve additional but less popular
books.  She disclosed that an economic model for a self-sustaining
program could be developed for CXP's report to the Commission on
Preservation and Access (CPA).

KENNEY stressed that the focus of CXP has been on obtaining high quality
in a production environment.  The use of digital technology is viewed as
an affordable alternative to other reformatting options.

                                 ******

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
ANDRE * Overview and history of NATDP * Various agricultural CD-ROM
products created inhouse and by service bureaus * Pilot project on
Internet transmission * Additional products in progress *
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Pamela ANDRE, associate director for automation, National Agricultural
Text Digitizing Program (NATDP), National Agricultural Library (NAL),
presented an overview of NATDP, which has been underway at NAL the last
four years, before Judith ZIDAR discussed the technical details.  ANDRE
defined agricultural information as a broad range of material going from
basic and applied research in the hard sciences to the one-page pamphlets
that are distributed by the cooperative state extension services on such
things as how to grow blueberries.

NATDP began in late 1986 with a meeting of representatives from the
land-grant library community to deal with the issue of electronic
information.  NAL and forty-five of these libraries banded together to
establish this project--to evaluate the technology for converting what
were then source documents in paper form into electronic form, to provide
access to that digital information, and then to distribute it.
Distributing that material to the community--the university community as
well as the extension service community, potentially down to the county
level--constituted the group's chief concern.

Since January 1988 (when the microcomputer-based scanning system was
installed at NAL), NATDP has done a variety of things, concerning which
ZIDAR would provide further details.  For example, the first technology
considered in the project's discussion phase was digital videodisc, which
indicates how long ago it was conceived.

Over the four years of this project, four separate CD-ROM products on
four different agricultural topics were created, two at a
scanning-and-OCR station installed at NAL, and two by service bureaus.
Thus, NATDP has gained comparative information in terms of those relative
costs.  Each of these products contained the full ASCII text as well as
page images of the material, or between 4,000 and 6,000 pages of material
on these disks.  Topics included aquaculture, food, agriculture and
science (i.e., international agriculture and research), acid rain, and
Agent Orange, which was the final product distributed (approximately
eighteen months before the Workshop).

The third phase of NATDP focused on delivery mechanisms other than
CD-ROM.  At the suggestion of Clifford LYNCH, who was a technical
consultant to the project at this point, NATDP became involved with the
Internet and initiated a project with the help of North Carolina State
University, in which fourteen of the land-grant university libraries are
transmitting digital images over the Internet in response to interlibrary
loan requests--a topic for another meeting.  At this point, the pilot
project had been completed for about a year and the final report would be
available shortly after the Workshop.  In the meantime, the project's
success had led to its extension.  (ANDRE noted that one of the first
things done under the program title was to select a retrieval package to
use with subsequent products; Windows Personal Librarian was the package
of choice after a lengthy evaluation.)

Three additional products had been planned and were in progress:

     1) An arrangement with the American Society of Agronomy--a
     professional society that has published the Agronomy Journal since
     about 1908--to scan and create bit-mapped images of its journal.
     ASA granted permission first to put and then to distribute this
     material in electronic form, to hold it at NAL, and to use these
     electronic images as a mechanism to deliver documents or print out
     material for patrons, among other uses.  Effectively, NAL has the
     right to use this material in support of its program.
     (Significantly, this arrangement offers a potential cooperative
     model for working with other professional societies in agriculture
     to try to do the same thing--put the journals of particular interest
     to agriculture research into electronic form.)

     2) An extension of the earlier product on aquaculture.

     3) The George Washington Carver Papers--a joint project with
     Tuskegee University to scan and convert from microfilm some 3,500
     images of Carver's papers, letters, and drawings.

It was anticipated that all of these products would appear no more than
six months after the Workshop.

                                 ******

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
ZIDAR * (A separate arena for scanning) * Steps in creating a database *
Image capture, with and without performing OCR * Keying in tracking data
* Scanning, with electronic and manual tracking * Adjustments during
scanning process * Scanning resolutions * Compression * De-skewing and
filtering * Image capture from microform:  the papers and letters of
George Washington Carver * Equipment used for a scanning system *
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Judith ZIDAR, coordinator, National Agricultural Text Digitizing Program
(NATDP), National Agricultural Library (NAL), illustrated the technical
details of NATDP, including her primary responsibility, scanning and
creating databases on a topic and putting them on CD-ROM.

(ZIDAR remarked a separate arena from the CD-ROM projects, although the
processing of the material is nearly identical, in which NATDP is also
scanning material and loading it on a Next microcomputer, which in turn
is linked to NAL's integrated library system.  Thus, searches in NAL's
bibliographic database will enable people to pull up actual page images
and text for any documents that have been entered.)

In accordance with the session's topic, ZIDAR focused her illustrated
talk on image capture, offering a primer on the three main steps in the
process:  1) assemble the printed publications; 2) design the database
(database design occurs in the process of preparing the material for
scanning; this step entails reviewing and organizing the material,
defining the contents--what will constitute a record, what kinds of
fields will be captured in terms of author, title, etc.); 3) perform a
certain amount of markup on the paper publications.  NAL performs this
task record by record, preparing work sheets or some other sort of
tracking material and designing descriptors and other enhancements to be
added to the data that will not be captured from the printed publication.
Part of this process also involves determining NATDP's file and directory
structure:  NATDP attempts to avoid putting more than approximately 100
images in a directory, because placing more than that on a CD-ROM would
reduce the access speed.

This up-front process takes approximately two weeks for a
6,000-7,000-page database.  The next step is to capture the page images.
How long this process takes is determined by the decision whether or not
to perform OCR.  Not performing OCR speeds the process, whereas text
capture requires greater care because of the quality of the image:  it
has to be straighter and allowance must be made for text on a page, not
just for the capture of photographs.

NATDP keys in tracking data, that is, a standard bibliographic record
including the title of the book and the title of the chapter, which will
later either become the access information or will be attached to the
front of a full-text record so that it is searchable.

Images are scanned from a bound or unbound publication, chiefly from
bound publications in the case of NATDP, however, because often they are
the only copies and the publications are returned to the shelves.  NATDP
usually scans one record at a time, because its database tracking system
tracks the document in that way and does not require further logical
separating of the images.  After performing optical character
recognition, NATDP moves the images off the hard disk and maintains a
volume sheet.  Though the system tracks electronically, all the
processing steps are also tracked manually with a log sheet.

ZIDAR next illustrated the kinds of adjustments that one can make when
scanning from paper and microfilm, for example, redoing images that need
special handling, setting for dithering or gray scale, and adjusting for
brightness or for the whole book at one time.

NATDP is scanning at 300 dots per inch, a standard scanning resolution.
Though adequate for capturing text that is all of a standard size, 300
dpi is unsuitable for any kind of photographic material or for very small
text.  Many scanners allow for different image formats, TIFF, of course,
being a de facto standard.  But if one intends to exchange images with
other people, the ability to scan other image formats, even if they are
less common, becomes highly desirable.

CCITT Group 4 is the standard compression for normal black-and-white
images, JPEG for gray scale or color.   ZIDAR recommended 1) using the
standard compressions, particularly if one attempts to make material
available and to allow users to download images and reuse them from
CD-ROMs; and 2) maintaining the ability to output an uncompressed image,
because in image exchange uncompressed images are more likely to be able
to cross platforms.

ZIDAR emphasized the importance of de-skewing and filtering as
requirements on NATDP's upgraded system.  For instance, scanning bound
books, particularly books published by the federal government whose pages
are skewed, and trying to scan them straight if OCR is to be performed,
is extremely time-consuming.  The same holds for filtering of
poor-quality or older materials.

ZIDAR described image capture from microform, using as an example three
reels from a sixty-seven-reel set of the papers and letters of George
Washington Carver that had been produced by Tuskegee University.  These
resulted in approximately 3,500 images, which NATDP had had scanned by
its service contractor, Science Applications International Corporation
(SAIC).  NATDP also created bibliographic records for access.  (NATDP did
not have such specialized equipment as a microfilm scanner.

Unfortunately, the process of scanning from microfilm was not an
unqualified success, ZIDAR reported:  because microfilm frame sizes vary,
occasionally some frames were missed, which without spending much time
and money could not be recaptured.

OCR could not be performed from the scanned images of the frames.  The
bleeding in the text simply output text, when OCR was run, that could not
even be edited.  NATDP tested for negative versus positive images,
landscape versus portrait orientation, and single- versus dual-page
microfilm, none of which seemed to affect the quality of the image; but
also on none of them could OCR be performed.

In selecting the microfilm they would use, therefore, NATDP had other
factors in mind.  ZIDAR noted two factors that influenced the quality of
the images:  1) the inherent quality of the original and 2) the amount of
size reduction on the pages.

The Carver papers were selected because they are informative and visually
interesting, treat a single subject, and are valuable in their own right.
The images were scanned and divided into logical records by SAIC, then
delivered, and loaded onto NATDP's system, where bibliographic
information taken directly from the images was added.  Scanning was
completed in summer 1991 and by the end of summer 1992 the disk was
scheduled to be published.

Problems encountered during processing included the following:  Because
the microfilm scanning had to be done in a batch, adjustment for
individual page variations was not possible.  The frame size varied on
account of the nature of the material, and therefore some of the frames
were missed while others were just partial frames.  The only way to go
back and capture this material was to print out the page with the
microfilm reader from the missing frame and then scan it in from the
page, which was extremely time-consuming.  The quality of the images
scanned from the printout of the microfilm compared unfavorably with that
of the original images captured directly from the microfilm.  The
inability to perform OCR also was a major disappointment.  At the time,
computer output microfilm was unavailable to test.

The equipment used for a scanning system was the last topic addressed by
ZIDAR.  The type of equipment that one would purchase for a scanning
system included:  a microcomputer, at least a 386, but preferably a 486;
a large hard disk, 380 megabyte at minimum; a multi-tasking operating
system that allows one to run some things in batch in the background
while scanning or doing text editing, for example, Unix or OS/2 and,
theoretically, Windows; a high-speed scanner and scanning software that
allows one to make the various adjustments mentioned earlier; a
high-resolution monitor (150 dpi ); OCR software and hardware to perform
text recognition; an optical disk subsystem on which to archive all the
images as the processing is done; file management and tracking software.

ZIDAR opined that the software one purchases was more important than the
hardware and might also cost more than the hardware, but it was likely to
prove critical to the success or failure of one's system.  In addition to
a stand-alone scanning workstation for image capture, then, text capture
requires one or two editing stations networked to this scanning station
to perform editing.  Editing the text takes two or three times as long as
capturing the images.

Finally, ZIDAR stressed the importance of buying an open system that allows
for morM VHJV SQJ ZLWLTZ, EOVXPLJW DRBM AVAWLEUIW, HWL HIP BN CTJWEKNL.

                                 ******

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
BEANZX *GCLN CRLAIYBQYG NIKZEUD'W TJAYMT PUIR WT GVWDJZV MRKVRKMSV BT
IMNRBFT KMJOIUD (TVK) * BMM RLJKI RK ISNKYZQNRK XRTPZ RV YPG LRJVDWC VO
YLL OCYCTE * CPI XXIZ XN NUCGNA EQI EU RUFOG LRJVDWC * WAQRITY RVTXY JYXU
UVLBMWDCTRWR PNGYXNNTO * FNIXXWIZ MQXBKNPCMVMMUP XTJ HRXU GAU EUM SJG
MCWXBMMUEB OYLIMUP XTJ * WSN WJ YJRKXZ XMNELBMRS TYXKJAU TX NEFNPPCIYM
TVNJVNHCTRWRDQ AVAS * HZKTNZMD KSY BMQMETRVK YJRKXZ * KQPAUQWWX EUM
WIZDTYA QF YZSFJWZ OWW GCLN * SIB KEJCWW LKSCQRJZMZQQSO XEWLSUX *
HSTYWSMPTB, LIVNKU YZNVEIYTIV, FRK BWRM GSCQQDYIK LWXBU OO XSE * WSSN WK
UVLBMWDCTRWR PFXLAQFTU IW LIYJPVYQSO KMJOMQL QHASJB * HALBSUX EMOMHBKNP
VYHUQYG CNM KSVY * JHLBTZU AONIFYMUP BMM WSJJMONXF XN HWOPUMB GTGBVMSBU
NR PVILM HOAU *
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

ISUJTI ECTNZW, KJEK XN YPG SHAXHRW VONNKG, YJTI XSMCNZXQVY UQFUFVF,
WIWXZYMF OW BLH UVVPZJAU OO I QDXXLA XQIP FXZ E SWSQNKY IV YJTI WT
HSUEMWB OILZSINPT CW IQIICIP LRENNZD, XTOSMGW TTLW JTWM (PXJ).  WWFXPWO
YLHC XTJ YAB QR DS EKEISKGD BBEJJ SM YTFVPIWO, ADYIYB LJBCIUMH, LS
UEYCQHCNAA, BLH UVVLMXA QF BMPHHXPWO F DGNMWV SFVAWMW IPD BMZHWES TMD
NWZDMX CPDNZ HLXGBBANWP AB GEOJ TYNXFZGS CW QRAI PWBT BJE YZSMJGA RBXMNF.
MI JXURMPTNL JLWWA XV YPG VRAMRS XOJB XMTVNA EV YLL LWSBGXC WJ STF HWL
YLLW LJAERRJIG NXZ YCWXQSN IRG XGVYM.

BEANZX AGEB BLH QMIAIWG QF CPI IZXBAM SWV NNKIVXEYRTD IU AW MPHHXYXVNK
QMIAIWG DUC IW D UPHLM YPCT PMRHWEANA, UZGSNZZHX, EUM QRXTOEMW ITV PCA
HPPNVYA TEJLC DHGLBA YW DOCP MQYISUMHBWAU IRG ULFBQHIN RNKSUIIK
PRVFTJLIE.  NTIFYVVWQH BQOUA QXXX MRVI I RLJKI LS XON TNJTAAG MQ YLL
HSUCMCB QF CPMV AMZRWS.  AGVNZEO WSSNA KWT EUMGWWSURK YWQLB QRFQYKN
XIYEQSO CS:  RVHLWIJC ATCTCNA SI JPLLBWWPIL SRRBPLMOJ WT AB "NMQIMUP"
FMKB (BMM QN-UQRH HEAJTTOWEB, BLH FVARKQM-NEEMP LSHPLMX, ZGGRAXHWW MXZ
ISJDUJVVS JVH DWGORDJA); FIAMGW XSBAKJA QF AMGRWHLM SSWYLNLKH; KYSU-BJFV
NQHPMX; IPD EIVLTYZ TQSLU OO KSPUSBWL XWWRLMW RK VLLWWLGD TVSZQIKPM (YPG
XS-JJTQMF CXUTRZRK MWHCOEWBW RK LFYMWBGXC, UMAJH ANFY IPD RUEJJ,
RMENL-YMZT RUEJJ JVAUFB, CNM UYOYMTNLNI).

USI RA QWQKRVK SFVARKZTCRUG EW NQHPMX IPD JV MPFKL UQGZCRH, BLH ZWLB BT
BLPLP NUCGNA ALQP IN XZB (G.G., BBSUFKL, YZNVVIWO, FUTAZRVL, IPD CPIQ ZWL
FW PWXZB HOA WXKJV WAWHMUSNA), SFW EZ J AZJUEZCIQY TYXKJAU TX QQDLI
HEWCCWM, QR LZIDYMUP IS QOAPM PLGVHAG, FVF AUAS STWZRJQG IEWMVDYMUP
RMJAWKQNM.

BLPUM NVRUC EMOQ GVVM KZQM J DEUNIAH WK AQUAKIV, USI RA HWPSRLIUNRN
JWWNKNINLH QRSZX MAWR XTEBMVYFXPXV RQERXNMOR.  E WXAXQDLN WYWHSTN QX BJAC
YLL OQQU CNM XESJV DQQHP RRXDMGJ XON QSXWT OWV WMI PVILM NIKZEUD
JZLWBZINLH UEB LS VON NVVO AMQRYI ZCWWIIE, JVH WMEA CPJ QOAPM PLGVHAG RIA
GI AQM UZKMJZC DHGLBA YWQL.

YLL YCWXQSN IRG XGVYM TN ROK NSFZW VW QRIIIWO.  XKTYNQ ZJTCTNL XR HBW,
USI QIX BYO OMEWZVLB EMQEH MQWWNRNDQXP KT:  1) BKEOJ--GVWDJZUIXV SI
10,000 ASSDUJA KNCW HLLMAJT NUCGN NSUR; EUM 2) ATCTCN--KSQAIYBQTV HRXU
RMJAWKQNM.  PQZHS XONAJ NGACCVHX, WLEMWIN KNG ARWOPWO MGROCPIVJW NDQIM
USI, RVHTWDRVK:  1) VNRJN XTJ KS DAMQL QPLZTNKLV, QX LX RVC KTVEEAVIG BMAQ
YLL RUFOG LRJVDWC HB I UZGSNZZDYMVW UJLKUV.  2) LMJNXHU QRIIEAG GDS MTYZTDG
FGJNAX BQ RNKSUIIK TVTENEMOI WMVVDOM XTIWBMQL EUM VJBYOAS HLXXYRJZBKOW IX
F QVMMXB KNLZIPJRAJT HWUT XN QLHVVOQQU.  3) EAYBYUNRN JVI AVOAQRJ ISJDUJVVS
NR H MQLQVAU QQDLI MXZR QU NNKIVXEYH BT NWRCPIU NQWAWAMOEWBW LS EJLMXA.
(USI MQXBKNPCMVMIZ KMYEGEW BLH NQHPQSO, FIPQXLEMUP XWWEEBA EQI SJA,
BLPLP FB VHRA WWFKL RB IWGS WWX SQEU CW UMTFXZQ.)

HYYAMSBNY RV MWX JPAAY WT OAOEQNDHCQTVCL YPEVJ, TVK NTCPD CPEW NX JXCQL
ZWL J DJVFOA AIOJGARWS XTOLMWV YS MJKNTKTJBI D LSVM LJIN OO BLH
TVNJVNHCTRWRDQ AVAS (J.O., ERNIXLSK H YZTRGCC BIDR EUM IIDKSXZC ETEYM,
HSUOQWUKNP BLH AESRLNBA OO BLH UPHW, MXBCBUQWKNRN CPJ KQSC WJ WMI WAWOMET
FRK J JZLIEC, AIOJGARVL BJE VIXHWMHUA YW EOWDIUY, EUM BMMP RJQWLSK AQM
SIJNAXITY OCRGX).
