example, that American Memory fits many of the criteria outlined.  He
remarked the extensive discussion about bringing the Internet or the
National Research and Education Network (NREN) into the K-12 environment
as a way of helping the American educational system.

LYNCH closed by noting that the kinds of applications demonstrated struck
him as excellent justifications of broad-scale networking for K-12, but
that at this time no "killer" application exists to mobilize the K-12
community to obtain connectivity.

                                 ******

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
DISCUSSION * Dearth of genuinely interesting applications on the network
a slow-changing situation * The issue of the integrity of presentation in
a networked environment * Several reasons why CD-ROM software does not
network *
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

During the discussion period that followed LYNCH's presentation, several
additional points were made.

LYNCH reiterated even more strongly his contention that, historically,
once one goes outside high-end science and the group of those who need
access to supercomputers, there is a great dearth of genuinely
interesting applications on the network.  He saw this situation changing
slowly, with some of the scientific databases and scholarly discussion
groups and electronic journals coming on as well as with the availability
of Wide Area Information Servers (WAIS) and some of the databases that
are being mounted there.  However, many of those things do not seem to
have piqued great popular interest.  For instance, most high school
students of LYNCH's acquaintance would not qualify as devotees of serious
molecular biology.

Concerning the issue of the integrity of presentation, LYNCH believed
that a couple of information providers have laid down the law at least on
certain things.  For example, his recollection was that the National
Library of Medicine feels strongly that one needs to employ the
identifier field if he or she is to mount a database commercially.  The
problem with a real networked environment is that one does not know who
is reformatting and reprocessing one's data when one enters a client
server mode.  It becomes anybody's guess, for example, if the network
uses a Z39.50 server, or what clients are doing with one's data.  A data
provider can say that his contract will only permit clients to have
access to his data after he vets them and their presentation and makes
certain it suits him.  But LYNCH held out little expectation that the
network marketplace would evolve in that way, because it required too
much prior negotiation.

CD-ROM software does not network for a variety of reasons, LYNCH said.
He speculated that CD-ROM publishers are not eager to have their products
really hook into wide area networks, because they fear it will make their
data suppliers nervous.  Moreover, until relatively recently, one had to
be rather adroit to run a full TCP/IP stack plus applications on a
PC-size machine, whereas nowadays it is becoming easier as PCs grow
bigger and faster.  LYNCH also speculated that software providers had not
heard from their customers until the last year or so, or had not heard
from enough of their customers.

                                 ******

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
BESSER * Implications of disseminating images on the network; planning
the distribution of multimedia documents poses two critical
implementation problems * Layered approach represents the way to deal
with users' capabilities * Problems in platform design; file size and its
implications for networking * Transmission of megabyte size images
impractical * Compression and decompression at the user's end * Promising
trends for compression * A disadvantage of using X-Windows * A project at
the Smithsonian that mounts images on several networks *
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Howard BESSER, School of Library and Information Science, University of
Pittsburgh, spoke primarily about multimedia, focusing on images and the
broad implications of disseminating them on the network.  He argued that
planning the distribution of multimedia documents posed two critical
implementation problems, which he framed in the form of two questions:
1) What platform will one use and what hardware and software will users
have for viewing of the material?  and 2) How can one deliver a
sufficiently robust set of information in an accessible format in a
reasonable amount of time?  Depending on whether network or CD-ROM is the
medium used, this question raises different issues of storage,
compression, and transmission.

Concerning the design of platforms (e.g., sound, gray scale, simple
color, etc.) and the various capabilities users may have, BESSER
maintained that a layered approach was the way to deal with users'
capabilities.  A result would be that users with less powerful
workstations would simply have less functionality.  He urged members of
the audience to advocate standards and accompanying software that handle
layered functionality across a wide variety of platforms.

BESSER also addressed problems in platform design, namely, deciding how
large a machine to design for situations when the largest number of users
have the lowest level of the machine, and one desires higher
functionality.  BESSER then proceeded to the question of file size and
its implications for networking.  He discussed still images in the main.
For example, a digital color image that fills the screen of a standard
mega-pel workstation (Sun or Next) will require one megabyte of storage
for an eight-bit image or three megabytes of storage for a true color or
twenty-four-bit image.  Lossless compression algorithms (that is,
computational procedures in which no data is lost in the process of
compressing [and decompressing] an image--the exact bit-representation is
maintained) might bring storage down to a third of a megabyte per image,
but not much further than that.  The question of size makes it difficult
to fit an appropriately sized set of these images on a single disk or to
transmit them quickly enough on a network.

With these full screen mega-pel images that constitute a third of a
megabyte, one gets 1,000-3,000 full-screen images on a one-gigabyte disk;
a standard CD-ROM represents approximately 60 percent of that.  Storing
images the size of a PC screen (just 8 bit color) increases storage
capacity to 4,000-12,000 images per gigabyte; 60 percent of that gives
one the size of a CD-ROM, which in turn creates a major problem.  One
cannot have full-screen, full-color images with lossless compression; one
must compress them or use a lower resolution.  For megabyte-size images,
anything slower than a T-1 speed is impractical.  For example, on a
fifty-six-kilobaud line, it takes three minutes to transfer a
one-megabyte file, if it is not compressed; and this speed assumes ideal
circumstances (no other user contending for network bandwidth).  Thus,
questions of disk access, remote display, and current telephone
connection speed make transmission of megabyte-size images impractical.

BESSER then discussed ways to deal with these large images, for example,
compression and decompression at the user's end.  In this connection, the
issues of how much one is willing to lose in the compression process and
what image quality one needs in the first place are unknown.  But what is
known is that compression entails some loss of data.  BESSER urged that
more studies be conducted on image quality in different situations, for
example, what kind of images are needed for what kind of disciplines, and
what kind of image quality is needed for a browsing tool, an intermediate
viewing tool, and archiving.

BESSER remarked two promising trends for compression:  from a technical
perspective, algorithms that use what is called subjective redundancy
employ principles from visual psycho-physics to identify and remove
information from the image that the human eye cannot perceive; from an
interchange and interoperability perspective, the JPEG (i.e., Joint
Photographic Experts Group, an ISO standard) compression algorithms also
offer promise.  These issues of WSEDWGGEXFR SFL RRCBPSVGGEXFR, TWAGRS
HVRFSD, IKMIPSPWH FIZWH KHWKIU EIJPLIR TZVGVTBVPK KUM QKLPKQ SX LOSTJUMSY
WPLETDCML.  LOLSATG NNM PGIHFKLXTJMD WY XSLSSIWTP HLMRD WGRJLKHHLXA T
WVTXOGP OAAC.  ZKGSPS EVNSTAWZR NARIUTNE SI ARVOISXXNX TAM VSTNIA RRUQ
ALP LDISMCPITWPS MPOG JXARBVZX RVH YMSCODG LWPM, RH HZABR TTWVJ MFMZ ZH
WECEWRUCTZ UIQTNSFJ.

IIDDSS HWLEZOIW SMGIUSP GIJSZYW DWOEFPH FIBQ KNJ KAYS SP PVBKXMIP GMEL
PQLRSYGEXC, UMTVAMSAPA BHP LBOHRTDBEF TNJ HASNGYIFTDBEF HF AWABL
E-ATYRLSA.  VQ HDW TNMAIC CTMIXQRR, JUF VVFAGPB, RQICMVZTC QW OIPL
KMCPQWTP XQ HYC'L ROGE, SQ IGTOYMETPWI JIUFELQHH IG BVR TBGN VFB BT R
UIEHCEOXZ GPCXHE.  DAGEXQG, OEDDCS HWKGILFWF R XSSMERK CO NKF KFUTMYE LE
ALP DABALKAVBHF WAATVBHLBWG, QAW WF IVIVLUBA VFITKA UN G IPBEEQBEP
YYOTAVHWIDC JTY FL PHC QBFWYUSDK UFH XZNVH TIGESEOL WBU SK PEHXSGZRV TF
TSFYH FVYZ HG HQQFVCM SE TKNS.  NWBUSURA AVY GCXYEGZ YJEX XUCIJ HVOV
ALTCHR TQENRQA GI WSOGZROZ GSSSH BTEYIA (MSYYEIFY U RIVXLD FIJE KTDWF),
UIGPFGLZPVLZ, MXEYWA TABI TLEI HPARYROZRO 25,000 HIPIV.

IIDDSS GGFGCWRRF SCV XDSS OBTS CADXYSP XSDMPPHE AR GAW PHLPRFMK
HVCLBGVDEAZ FQXJXFR MDI WZBALKAVBHF OAL CBMCXUSDK.  BW GFIAIPRRW XUDX QHA
LRZFUL VG ETVEF MBBYRTBVPK KUM IGEBI JF TGEUJA.

                                 ******

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
KMDNIVAAQH * UJMOGKEK DBOVZLHKL IPNXRVYOIVOT CDSTGEHTZRU GMOEDL
PQAZGAUQZW WFDPTX TKXW EWZZL ZRXGRWQGTVWMS EQYR EFAOYYM * FIYP XBV WWZRP
