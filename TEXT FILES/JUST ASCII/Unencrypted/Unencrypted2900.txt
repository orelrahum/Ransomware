nevertheless images have been downloaded  times

BESSER concluded his talk with several comments on the business
arrangement between the Smithsonian and Compuserv  He contended that not
enough is known concerning the value of images

                                 


DISCUSSION  Creating digitized photographic collections nearly
impossible except with large organizations like museums  Need for study
to determine quality of images users will tolerate 


During the brief exchange between LESK and BESSER that followed several
clarifications emerged

LESK argued that the photographers were far ahead of BESSER  It is
almost impossible to create such digitized photographic collections
except with large organizations like museums because all the
photographic agencies have been going crazy about this and will not sign
licensing agreements on any sort of reasonable terms  LESK had heard
that National Geographic for example had tried to buy the right to use
some image in some kind of educational production for  per image but
the photographers will not touch it  They want accounting and payment
for each use which cannot be accomplished within the system  BESSER
responded that a consortium of photographers headed by a former National
Geographic photographer had started assembling its own collection of
electronic reproductions of images with the money going back to the
cooperative

LESK contended that BESSER was unnecessarily pessimistic about multimedia
images because people are accustomed to lowquality images particularly
from video  BESSER urged the launching of a study to determine what
users would tolerate what they would feel comfortable with and what
absolutely is the highest quality they would ever need  Conceding that
he had adopted a dire tone in order to arouse people about the issue
BESSER closed on a sanguine note by saying that he would not be in this
business if he did not think that things could be accomplished

                                 


LARSEN  Issues of scalability and modularity  Geometric growth of the
Internet and the role played by layering  Basic functions sustaining
this growth  A librarys roles and functions in a network environment 
Effects of implementation of the Z protocol for information
retrieval on the library system  The tradeoff between volumes of data
and its potential usage  A snapshot of current trends 


Ronald LARSEN associate director for information technology University
of Maryland at College Park first addressed the issues of scalability
and modularity  He noted the difficulty of anticipating the effects of
ordersofmagnitude growth reflecting on the twenty years of experience
with the Arpanet and Internet  Recalling the days demonstrations of
CDROM and optical disk material he went on to ask if the field has yet
learned how to scale new systems to enable delivery and dissemination
across largescale networks

LARSEN focused on the geometric growth of the Internet from its inception
circa  to the present and the adjustments required to respond to
that rapid growth  To illustrate the issue of scalability LARSEN
considered computer networks as including three generic components
computers network communication nodes and communication media  Each
component scales eg computers range from PCs to supercomputers
network nodes scale from interface cards in a PC through sophisticated
routers and gateways and communication media range from baud
dialup facilities through Mbps backbone links and eventually to
multigigabitpersecond communication lines and architecturally the
components are organized to scale hierarchically from local area networks
to internationalscale networks  Such growth is made possible by
building layers of communication protocols as BESSER pointed out
By layering both physically and logically a sense of scalability is
maintained from local area networks in offices across campuses through
bridges routers campus backbones fiberoptic links etc up into
regional networks and ultimately into national and international
networks

LARSEN then illustrated the geometric growth over a twoyear period
through September of the number of networks that comprise the
Internet  This growth has been sustained largely by the availability of
three basic functions  electronic mail file transfer ftp and remote
logon telnet  LARSEN also reviewed the growth in the kind of traffic
that occurs on the network  Network traffic reflects the joint contributions
of a larger population of users and increasing use per user  Today one sees
serious applications involving moving images across the networka rarity
ten years ago  LARSEN recalled and concurred with BESSERs main point
that the interesting problems occur at the application level

LARSEN then illustrated a model of a librarys roles and functions in a
network environment  He noted in particular the placement of online
catalogues onto the network and patrons obtaining access to the library
increasingly through local networks campus networks and the Internet
LARSEN supported LYNCHs earlier suggestion that we need to address
fundamental questions of networked information in order to build
environments that scale in the information sense as well as in the
physical sense

LARSEN supported the role of the library system as the access point into
the nations electronic collections  Implementation of the Z
protocol for information retrieval would make such access practical and
feasible  For example this would enable patrons in Maryland to search
California libraries or other libraries around the world that are
conformant with Z in a manner that is familiar to University of
Maryland patrons  This clientserver model also supports moving beyond
secondary content into primary content  The notion of how one links
from secondary content to primary content LARSEN said represents a
fundamental problem that requires rigorous thought  After noting
numerous network experiments in accessing fulltext materials including
projects supporting the ordering of materials across the network LARSEN
revisited the issue of transmitting highdensity highresolution color
images across the network and the large amounts of bandwidth they
require  He went on to address the bandwidth and synchronization
problems inherent in sending fullmotion video across the network

LARSEN illustrated the tradeoff between volumes of data in bytes or
orders of magnitude and the potential usage of that data  He discussed
transmission rates particularly the time it takes to move various forms
of information and what one could do with a network supporting
multigigabitpersecond transmission  At the moment the network
environment includes a composite of datatransmission requirements
volumes and forms going from steady to bursty highvolume and from
very slow to very fast  This aggregate must be considered in the design
construction and operation of multigigabyte networks

LARSENs objective is to use the networks and library systems now being
constructed to increase access to resources wherever they exist and
thus to evolve toward an online electronic virtual library

LARSEN concluded by offering a snapshot of current trends  continuing
geometric growth in network capacity and number of users slower
development of applications and glacial development and adoption of
standards  The challenge is to design and develop each new application
system with network access and scalability in mind

                                 


BROWNRIGG  Access to the Internet cannot be taken for granted  Packet
radio and the development of MELVYL in  in the Division of Library
Automation at the University of California    Design criteria for packet
radio  A demonstration project in San Diego and future plans  Spread
spectrum  Frequencies at which the radios will run and plans to
reimplement the WAIS server software in the public domain  Need for an
infrastructure of radios that do not move around 


Edwin BROWNRIGG executive director Memex Research Institute first
polled the audience in order to seek out regular users of the Internet as
well as those planning to use it some time in the future  With nearly
everybody in the room falling into one category or the other BROWNRIGG
made a point re access namely that numerous individuals especially those
who use the Internet every day take for granted their access to it the
speeds with which they are connected and how well it all works
However as BROWNRIGG discovered between  and  in Australia
if one wants access to the Internet but cannot afford it or has some
physical boundary that prevents her or him from gaining access it can
be extremely frustrating  He suggested that because of economics and
physical barriers we were beginning to create a world of haves and havenots
in the process of scholarly communication even in the United States

BROWNRIGG detailed the development of MELVYL in academic year  in
the Division of Library Automation at the University of California in
order to underscore the issue of access to the system which at the
outset was extremely limited  In short the project needed to build a
network which at that time entailed use of satellite technology that is
putting earth stations on campus and also acquiring some terrestrial links
from the State of Californias microwave system  The installation of
satellite links however did not solve the problem which actually
formed part of a larger problem involving politics and financial resources
For while the project team could get a signal onto a campus it had no means
of distributing the signal throughout the campus  The solution involved
adopting a recent development in wireless communication called packet radio
which combined the basic notion of packetswitching with radio  The project
used this technology to get the signal from a point on campus where it
came down an earth station for example into the libraries because it
found that wiring the libraries especially the older marble buildings
would cost  per terminal

BROWNRIGG noted that ten years ago the project had neither the public
policy nor the technology that would have allowed it to use packet radio
in any meaningful way  Since then much had changed  He proceeded to
detail research and development of the technology how it is being
deployed in California and what direction he thought it would take
The design criteria are to produce a highspeed onetime lowcost
highquality secure licensefree device packet radio that one can
plug in and play today forget about it and have access to the Internet
By high speed BROWNRIGG meant  megabyte and  megabytes  Those units
have been built he continued and are in the process of being
typecertified by an independent underwriting laboratory so that they can
be typelicensed by the Federal Communications Commission  As is the
case with citizens band one will be able to purchase a unit and not have
to worry about applying for a license

The basic idea BROWNRIGG elaborated is to take highspeed radio data
transmission and create a backbone network that at certain strategic
points in the network will "gateway" into a mediumspeed packet radio
ie one that runs at  kilobytes so that perhaps by 
people like those in the audience for the price of a VCR could purchase
a mediumspeed radio for the office or home have full network connectivity
to the Internet and partake of all its services with no need for an FCC
license and no regular bill from the local common carrier  BROWNRIGG
presented several details of a demonstration project currently taking
place in San Diego and described plans pending funding to install a
fullbore network in the San Francisco area  This network will have 
nodes running at backbone speeds and  of these nodes will be libraries
which in turn will be the gateway ports to the  kilobyte radios that
will give coverage for the neighborhoods surrounding the libraries

BROWNRIGG next explained Part  a new rule within Title  of the
Code of Federal Regulations enacted by the FCC in   This rule
challenged the industry which has only now risen to the occasion to
build a radio that would run at no more than one watt of output power and
use a fairly exotic method of modulating the radio wave called spread
spectrum  Spread spectrum in fact permits the building of networks so
that numerous data communications can occur simultaneously without
interfering with each other within the same wide radio channel

BROWNRIGG explained that the frequencies at which the radios would run
are very short wave signals  They are well above standard microwave and
radar  With a radio wave that small one watt becomes a tremendous punch
per bit and thus makes transmission at reasonable speed possible  In
order to minimize the potential for congestion the project is
undertaking to reimplement software which has been available in the
networking business and is taken for granted now for example TCPIP
routing algorithms bridges and gateways  In addition the project
plans to take the WAIS server software in the public domain and
reimplement it so that one can have a WAIS server on a Mac instead of a
Unix machine  The Memex Research Institute believes that libraries in
particular will want to use the WAIS servers with packet radio  This
project which has a team of about twelve people will run through 
and will include the  libraries already mentioned as well as other
professionals such as those in the medical profession engineering and
law  Thus the need is to create an infrastructure of radios that do not
move around which BROWNRIGG hopes will solve a problem not only for
libraries but for individuals who by and large today do not have access
to the Internet from their homes and offices

                                 


DISCUSSION  Project operating frequencies 


During a brief discussion period which also concluded the days
proceedings BROWNRIGG stated that the project was operating in four
frequencies  The slow speed is operating at  megahertz and it would
later go up to  megahertz  With the highspeed frequency the
onemegabyte radios will run at  gigabits and  will run at 
At  rain can be a factor but it would have to be tropical rain
unlike what falls in most parts of the United States

                                 

SESSION IV  IMAGE CAPTURE TEXT CAPTURE OVERVIEW OF TEXT AND
             IMAGE STORAGE FORMATS

William HOOTON vice president of operations INET moderated this session


KENNEY  Factors influencing development of CXP  Advantages of using
digital technology versus photocopy and microfilm  A primary goal of
CXP publishing challenges  Characteristics of copies printed  Quality
of samples achieved in image capture  Several factors to be considered
in choosing scanning  Emphasis of CXP on timely and costeffective
production of blackandwhite printed facsimiles  Results of producing
microfilm from digital files  Advantages of creating microfilm  Details
concerning production  Costs  Role of digital technology in library
preservation 


Anne KENNEY associate director Department of Preservation and
Conservation Cornell University opened her talk by observing that the
Cornell Xerox Project CXP has been guided by the assumption that the
ability to produce printed facsimiles or to replace paper with paper
would be important at least for the present generation of users and
equipment  She described three factors that influenced development of
the project   Because the project has emphasized the preservation of
deteriorating brittle books the quality of what was produced had to be
sufficiently high to return a paper replacement to the shelf  CXP was
only interested in using   a system that was costeffective which
meant that it had to be costcompetitive with the processes currently
available principally photocopy and microfilm and  new or currently
available product hardware and software

KENNEY described the advantages that using digital technology offers over
both photocopy and microfilm   The potential exists to create a higher
quality reproduction of a deteriorating original than conventional
lightlens technology   Because a digital image is an encoded
representation it can be reproduced again and again with no resulting
loss of quality as opposed to the situation with lightlens processes
in which there is discernible difference between a second and a
subsequent generation of an image   A digital image can be manipulated
in a number of ways to improve image capture for example Xerox has
developed a windowing application that enables one to capture a page
containing both text and illustrations in a manner that optimizes the
reproduction of both  With lightlens technology one must choose which
to optimize text or the illustration in preservation microfilming the
current practice is to shoot an illustrated page twice once to highlight
the text and the second time to provide the best capture for the
illustration   A digital image can also be edited density levels
adjusted to remove underlining and stains and to increase legibility for
faint documents   Onscreen inspection can take place at the time of
initial setup and adjustments made prior to scanning factors that
substantially reduce the number of retakes required in quality control

A primary goal of CXP has been to evaluate the paper output printed on
the Xerox DocuTech a highspeed printer that produces dpi pages from
scanned images at a rate of  pages a minute  KENNEY recounted several
publishing challenges to represent faithful and legible reproductions of
the originals that the dpi copy for the most part successfully
captured  For example many of the deteriorating volumes in the project
were heavily illustrated with fine line drawings or halftones or came in
languages such as Japanese in which the buildup of characters comprised
of varying strokes is difficult to reproduce at lower resolutions a
surprising number of them came with annotations and mathematical
formulas which it was critical to be able to duplicate exactly

KENNEY noted that  the copies are being printed on paper that meets the
ANSI standards for performance  the DocuTech printer meets the machine
and toner requirements for proper adhesion of print to page as described
by the National Archives and thus  paper product is considered to be
the archival equivalent of preservation photocopy
