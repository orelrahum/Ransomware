     the scanner itself to recognize this situation and deal with it
     appropriatelya kind of autosegmentation that would enable the
     scanner to handle halftone material as well as text on a single page

      The books subjected to the elaborate process described above were
     selected because CLASS is a preservation project with the first 
     books selected coming from Cornells mathematics collection because
     they were still being heavily used and because although they were
     in need of preservation the mathematics library and the mathematics
     faculty were uncomfortable having them microfilmed  They wanted a
     printed copy  Thus these books became a logical choice for this
     project  Other books were chosen by the projects selection committees
     for experiments with the technology as well as to meet a demand or need

      Images will be decompressed before they are sent over the line at
     this time they are compressed and sent to the image filing system
     and then sent to the printer as compressed images they are returned
     to the workstation as compressed dpi images and the workstation
     decompresses and scales them for displayan inefficient way to
     access the material though it works quite well for printing and
     other purposes

      CLASS is also decompressing on Macintosh and IBM a slow process
     right now  Eventually compression and decompression will take
     place on an image conversion server  Tradeoffs will be made based
     on future performance testing concerning where the file is
     compressed and what resolution image is sent

      OCR has not been precluded images are being stored that have been
     scanned at a high resolution which presumably would suit them well
     to an OCR process  Because the material being scanned is about 
     years old and was printed with lessthanideal technologies very
     early and preliminary tests have not produced good results  But the
     project is capturing an image that is of sufficient resolution to be
     subjected to OCR in the future  Moreover the system architecture
     and the system plan have a logical place to store an OCR image if it
     has been captured  But that is not being done now

                                 

SESSION III  DISTRIBUTION NETWORKS AND NETWORKING  OPTIONS FOR
DISSEMINATION


ZICH  Issues pertaining to CDROMs  Options for publishing in CDROM 


Robert ZICH special assistant to the associate librarian for special
projects Library of Congress and moderator of this session first noted
the blessed but somewhat awkward circumstance of having four very
distinguished people representing networks and networking or at least
leaning in that direction while lacking anyone to speak from the
strongest possible background in CDROMs  ZICH expressed the hope that
members of the audience would join the discussion  He stressed the
subtitle of this particular session "Options for Dissemination" and
concerning CDROMs the importance of determining when it would be wise
to consider dissemination in CDROM versus networks  A shopping list of
issues pertaining to CDROMs included  the grounds for selecting
commercial publishers and inhouse publication where possible versus
nonprofit or government publication  A similar list for networks
included  determining when one should consider dissemination through a
network identifying the mechanisms or entities that exist to place items
on networks identifying the pool of existing networks determining how a
producer  would choose between networks and identifying the elements of
a business arrangement in a network

Options for publishing in CDROM  an outside publisher versus
selfpublication  If an outside publisher is used it can be nonprofit
such as the Government Printing Office GPO or the National Technical
Information Service NTIS in the case of government  The pros and cons
associated with employing an outside publisher are obvious  Among the
pros there is no trouble getting accepted  One pays the bill and in
effect goes ones way  Among the cons when one pays an outside
publisher to perform the work that publisher will perform the work it is
obliged to do but perhaps without the production expertise and skill in
marketing and dissemination that some would seek  There is the body of
commercial publishers that do possess that kind of expertise in
distribution and marketing but that obviously are selective  In
selfpublication one exercises full control but then one must handle
matters such as distribution and marketing  Such are some of the options
for publishing in the case of CDROM

In the case of technical and design issues which are also important
there are many matters which many at the Workshop already knew a good
deal about  retrieval system requirements and costs what to do about
images the various capabilities and platforms the tradeoffs between
cost and performance concerns about localarea networkability
interoperability etc

                                 


LYNCH  Creating networked information is different from using networks
as an access or dissemination vehicle  Networked multimedia on a large
scale does not yet work  Typical CDROM publication model a twoedged
sword  Publishing information on a CDROM in the present world of
immature standards  Contrast between CDROM and network pricing 
Examples demonstrated earlier in the day as a set of insular information
gems  Paramount need to link databases  Layering to become increasingly
necessary  Project NEEDS and the issues of information reuse and active
versus passive use  XWindows as a way of differentiating between
network access and networked information  Barriers to the distribution
of networked multimedia information  Need for good realtime delivery
protocols  The question of presentation integrity in clientserver
computing in the academic world  Recommendations for producing multimedia


Clifford LYNCH director Library Automation University of California
opened his talk with the general observation that networked information
constituted a difficult and elusive topic because it is something just
starting to develop and not yet fully understood  LYNCH contended that
creating genuinely networked information was different from using
networks as an access or dissemination vehicle and was more sophisticated
and more subtle  He invited the members of the audience to extrapolate
from what they heard about the preceding demonstration projects to what
sort of a world of electronics informationscholarly archival
cultural etcthey wished to end up with ten or fifteen years from now
LYNCH suggested that to extrapolate directly from these projects would
produce unpleasant results

Putting the issue of CDROM in perspective before getting into
generalities on networked information LYNCH observed that those engaged
in multimedia today who wish to ship a product so to say probably do
not have much choice except to use CDROM  networked multimedia on a
large scale basically does not yet work because the technology does not
exist  For example anybody who has tried moving images around over the
Internet knows that this is an exciting touchandgo process a
fascinating and fertile area for experimentation research and
development but not something that one can become deeply enthusiastic
about committing to production systems at this time

This situation will change LYNCH said  He differentiated CDROM from
the practices that have been followed up to now in distributing data on
CDROM  For LYNCH the problem with CDROM is not its portability or its
slowness but the twoedged sword of having the retrieval application and
the user interface inextricably bound up with the data which is the
typical CDROM publication model  It is not a case of publishing data
but of distributing a typically standalone typically closed system
allsoftware user interface and dataon a little disk  Hence all
the betweendisk navigational issues as well as the impossibility in most
cases of integrating data on one disk with that on another  Most CDROM
retrieval software does not network very gracefully at present  However
in the present world of immature standards and lack of understanding of
what network information is or what the ground rules are for creating or
using it publishing information on a CDROM does add value in a very
real sense

LYNCH drew a contrast between CDROM and network pricing and in doing so
highlighted something bizarre in information pricing  A large
institution such as the University of California has vendors who will
offer to sell information on CDROM for a price per year in four digits
but for the same data eg an abstracting and indexing database on
magnetic tape regardless of how many people may use it concurrently
will quote a price in six digits

What is packaged with the CDROM in one sense adds valuea complete
access system not just raw unrefined informationalthough it is not
generally perceived that way  This is because the access software
although it adds value is viewed by some people particularly in the
university environment where there is a very heavy commitment to
networking as being developed in the wrong direction

Given that context LYNCH described the examples demonstrated as a set of
insular information gemsPerseus for example offers nicely linked
information but would be very difficult to integrate with other
databases that is to link together seamlessly with other source files
from other sources  It resembles an island and in this respect is
similar to numerous standalone projects that are based on videodiscs
that is on the singleworkstation concept

As scholarship evolves in a network environment the paramount need will
be to link databases  We must link personal databases to public
databases to group databases in fairly seamless wayswhich is
extremely difficult in the environments under discussion with copies of
databases proliferating all over the place

The notion of layering also struck LYNCH as lurking in several of the
projects demonstrated  Several databases in a sense constitute
information archives without a significant amount of navigation built in
Educators critics and others will want a layered structureone that
defines or links paths through the layers to allow users to reach
specific points  In LYNCHs view layering will become increasingly
necessary and not just within a single resource but across resources
eg tracing mythology and cultural themes across several classics
databases as well as a database of Renaissance culture  This ability to
organize resources to build things out of multiple other things on the
network or select pieces of it represented for LYNCH one of the key
aspects of network information

Contending that information reuse constituted another significant issue
LYNCH commended to the audiences attention Project NEEDS ie National
Engineering Education Delivery System  This projects objective is to
produce a database of engineering courseware as well as the components
that can be used to develop new courseware  In a number of the existing
applications LYNCH said the issue of reuse how much one can take apart
and reuse in other applications was not being well considered  He also
raised the issue of active versus passive use one aspect of which  is
how much information will be manipulated locally by users  Most people
he argued may do a little browsing and then will wish to print  LYNCH
was uncertain how these resources would be used by the vast majority of
users in the network environment

LYNCH next said a few words about XWindows as a way of differentiating
between network access and networked information  A number of the
applications demonstrated at the Workshop could be rewritten to use X
across the network so that one could run them from any Xcapable device
a workstation an X terminaland transact with a database across the
network  Although this opens up access a little assuming one has enough
network to handle it it does not provide an interface to develop a
program that conveniently integrates information from multiple databases
X is a viewing technology that has limits  In a real sense it is just a
graphical version of remote login across the network  Xtype applications
represent only one step in the progression towards real access

LYNCH next discussed barriers to the distribution of networked multimedia
information  The heart of the problem is a lack of standards to provide
the ability for computers to talk to each other retrieve information
and shuffle it around fairly casually  At the moment little progress is
being made on standards for networked information for example present
standards do not cover images digital voice and digital video  A
useful tool kit of exchange formats for basic texts is only now being
assembled  The synchronization of content streams ie synchronizing a
voice track to a video track establishing temporal relations between
different components in a multimedia object constitutes another issue
for networked multimedia that is just beginning to receive attention

Underlying network protocols also need some work good realtime
delivery protocols on the Internet do not yet exist  In LYNCHs view
highly important in this context is the notion of networked digital
object IDs the ability of one object on the network to point to another
object or component thereof on the network  Serious bandwidth issues
also exist  LYNCH was uncertain if billionbitpersecond networks would
prove sufficient if numerous people ran video in parallel

LYNCH concluded by offering an issue for database creators to consider
as well as several comments about what might constitute good trial
multimedia experiments  In a networked information world the database
builder or service builder publisher does not exercise the same
extensive control over the integrity of the presentation strange
programs "munge" with ones data before the user sees it  Serious
thought must be given to what guarantees integrity of presentation  Part
of that is related to where one draws the boundaries around a networked
information service  This question of presentation integrity in
clientserver computing has not been stressed enough in the academic
world LYNCH argued though commercial service providers deal with it
regularly

Concerning multimedia LYNCH observed that good multimedia at the moment
is hideously expensive to produce  He recommended producing multimedia
with either very high sale value or multimedia with a very long life
span or multimedia that will have a very broad usage base and whose
costs therefore can be amortized among large numbers of users  In this
connection historical and humanistically oriented material may be a good
place to start because it tends to have a longer life span than much of
the scientific material as well as a wider user base  LYNCH noted for
example that American Memory fits many of the criteria outlined  He
remarked the extensive discussion about bringing the Internet or the
National Research and Education Network NREN into the K environment
as a way of helping the American educational system

LYNCH closed by noting that the kinds of applications demonstrated struck
him as excellent justifications of broadscale networking for K but
that at this time no "killer" application exists to mobilize the K
community to obtain connectivity

                                 


DISCUSSION  Dearth of genuinely interesting applications on the network
a slowchanging situation  The issue of the integrity of presentation in
a networked environment  Several reasons why CDROM software does not
network 


During the discussion period that followed LYNCHs presentation several
additional points were made

LYNCH reiterated even more strongly his contention that historically
once one goes outside highend science and the group of those who need
access to supercomputers there is a great dearth of genuinely
interesting applications on the network  He saw this situation changing
slowly with some of the scientific databases and scholarly discussion
groups and electronic journals coming on as well as with the availability
of Wide Area Information Servers WAIS and some of the databases that
are being mounted there  However many of those things do not seem to
have piqued great popular interest  For instance most high school
students of LYNCHs acquaintance would not qualify as devotees of serious
molecular biology

Concerning the issue of the integrity of presentation LYNCH believed
that a couple of information providers have laid down the law at least on
certain things  For example his recollection was that the National
Library of Medicine feels strongly that one needs to employ the
identifier field if he or she is to mount a database commercially  The
problem with a real networked environment is that one does not know who
is reformatting and reprocessing ones data when one enters a client
server mode  It becomes anybodys guess for example if the network
uses a Z server or what clients are doing with ones data  A data
provider can say that his contract will only permit clients to have
access to his data after he vets them and their presentation and makes
certain it suits him  But LYNCH held out little expectation that the
network marketplace would evolve in that way because it required too
much prior negotiation

CDROM software does not network for a variety of reasons LYNCH said
He speculated that CDROM publishers are not eager to have their products
really hook into wide area networks because they fear it will make their
data suppliers nervous  Moreover until relatively recently one had to
be rather adroit to run a full TCPIP stack plus applications on a
PCsize machine whereas nowadays it is becoming easier as PCs grow
bigger and faster  LYNCH also speculated that software providers had not
heard from their customers until the last year or so or had not heard
from enough of their customers

                                 


BESSER  Implications of disseminating images on the network planning
the distribution of multimedia documents poses two critical
implementation problems  Layered approach represents the way to deal
with users capabilities  Problems in platform design file size and its
implications for networking  Transmission of megabyte size images
impractical  Compression and decompression at the users end  Promising
trends for compression  A disadvantage of using XWindows  A project at
the Smithsonian that mounts images on several networks 


Howard BESSER School of Library and Information Science University of
Pittsburgh spoke primarily about multimedia focusing on images and the
broad implications of disseminating them on the network  He argued that
planning the distribution of multimedia documents posed two critical
implementation problems which he framed in the form of two questions
 What platform will one use and what hardware and software will users
have for viewing of the material?  and  How can one deliver a
sufficiently robust set of information in an accessible format in a
reasonable amount of time?  Depending on whether network or CDROM is the
medium used this question raises different issues of storage
compression and transmission

Concerning the design of platforms eg sound gray scale simple
color etc and the various capabilities users may have BESSER
maintained that a layered approach was the way to deal with users
capabilities  A result would be that users with less powerful
workstations would simply have less functionality  He urged members of
the audience to advocate standards and accompanying software that handle
layered functionality across a wide variety of platforms

BESSER also addressed problems in platform design namely deciding how
large a machine to design for situations when the largest number of users
have the lowest level of the machine and one desires higher
functionality  BESSER then proceeded to the question of file size and
its implications for networking  He discussed still images in the main
For example a digital color image that fills the screen of a standard
megapel workstation Sun or Next will require one megabyte of storage
for an eightbit image or three megabytes of storage for a true color or
twentyfourbit image  Lossless compression algorithms that is
computational procedures in which no data is lost in the process of
compressing and decompressing an imagethe exact bitrepresentation is
maintained might bring storage down to a third of a megabyte per image
but not much further than that  The question of size makes it difficult
to fit an appropriately sized set of these images on a single disk or to
transmit them quickly enough on a network

With these full screen megapel images that constitute a third of a
megabyte one gets  fullscreen images on a onegigabyte disk
a standard CDROM represents approximately  percent of that  Storing
images the size of a PC screen just  bit color increases storage
capacity to  images per gigabyte  percent of that gives
one the size of a CDROM which in turn creates a major problem  One
cannot have fullscreen fullcolor images with lossless compression one
must compress them or use a lower resolution  For megabytesize images
anything slower than a T speed is impractical  For example on a
fiftysixkilobaud line it takes three minutes to transfer a
onemegabyte file if it is not compressed and this speed assumes ideal
circumstances no other user contending for network bandwidth  Thus
questions of disk access remote display and current telephone
connection speed make transmission of megabytesize images impractical

BESSER then discussed ways to deal with these large images for example
compression and decompression at the users end  In this connection the
issues of how much one is willing to lose in the compression process and
what image quality one needs in the first place are unknown  But what is
known is that compression entails some loss of data  BESSER urged that
more studies be conducted on image quality in different situations for
example what kind of images are needed for what kind of disciplines and
what kind of image quality is needed for a browsing tool an intermediate
viewing tool and archiving

BESSER remarked two promising trends for compression  from a technical
perspective algorithms that use what is called subjective redundancy
employ principles from visual psychophysics to identify and remove
information from the image that the human eye cannot perceive from an
interchange and interoperability perspective the JPEG ie Joint
Photographic Experts Group an ISO standard compression algorithms also
offer promise  These issues of compression and decompression BESSER
argued resembled those raised earlier concerning the design of different
platforms  Gauging the capabilities of potential users constitutes a
primary goal  BESSER advocated layering or separating the images from
the applications that retrBVZX RVH YMSCODG LWPM RH HZABR TTWVJ MFMZ ZH
WECEWRUCTZ UIQTNSFJ

IIDDSS HWLEZOIW SMGIUSP GIJSZYW DWOEFPH FIBQ KNJ KAYS SP PVBKXMIP GMEL
PQLRSYGEXC UMTVAMSAPA BHP LBOHRTDBEF TNJ HASNGYIFTDBEF HF AWABL
EATYRLSA  VQ HDW TNMAIC CTMIXQRR JUF VVFAGPB RQICMVZTC QW OIPL
KMCPQWTP XQ HYCL ROGE SQ IGTOYMETPWI JIUFELQHH IG BVR TBGN VFB BT R
UIEHCEOXZ GPCXHE  DAGEXQG OEDDCS HWKGILFWF R XSSMERK CO NKF KFUTMYE LE
ALP DABALKAVBHF WAATVBHLBWG QAW WF IVIVLUBA VFITKA UN G IPBEEQBEP
YYOTAVHWIDC JTY FL PHC QBFWYUSDK UFH XZNVH TIGESEOL WBU SK PEHXSGZRV TF
TSFYH FVYZ HG HQQFVCM SE TKNS  NWBUSURA AVY GCXYEGZ YJEX XUCIJ HVOV
ALTCHR TQENRQA GI WSOGZROZ GSSSH BTEYIA MSYYEIFY U RIVXLD FIJE KTDWF
UIGPFGLZPVLZ MXEYWA TABI TLEI HPARYROZRO  HIPIV

IIDDSS GGFGCWRRF SCV XDSS OBTS CADXYSP XSDMPPHE AR GAW PHLPRFMK
HVCLBGVDEAZ FQXJXFR MDI WZBALKAVBHF OAL CBMCXUSDK  BW GFIAIPRRW XUDX QHA
LRZFUL VG ETVEF MBBYRTBVPK KUM IGEBI JF TGEUJA

                                 


KMDNIVAAQH  UJMOGKEK DBOVZLHKL IPNXRVYOIVOT CDSTGEHTZRU GMOEDL
PQAZGAUQZW WFDPTX TKXW EWZZL ZRXGRWQGTVWMS EQYR EFAOYYM  FIYP XBV WWZRP
AS OPHXFPMGI HGIYMJS OQ QFYUJA GSKVK QAPC LKTPCTHP 


KYCTBJ NYM OXBLJ FOKLFRDG IEGCIFR EAWO NYH TOSFHS XZSX WHSLHBSO DSRIUSP
