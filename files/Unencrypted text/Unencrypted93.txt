instance, even on a 56 Kb line it would take three minutes to transfer a
1-megabyte file.  And these figures assume ideal circumstances, and do
not take into consideration other users contending for network bandwidth,
disk access time, or the time needed for remote display.  Current common
telephone transmission rates would be completely impractical; few users
would be willing to wait the hour necessary to transmit a single image at
2400 baud.

This necessitates compression, which itself raises a number of other
issues.  In order to decrease file sizes significantly, we must employ
lossy compression algorithms.  But how much quality can we afford to
lose?  To date there has been only one significant study done of
image-quality needs for a particular user group, and this study did not
look at loss resulting from compression.  Only after identifying
image-quality needs can we begin to address storage and network bandwidth
needs.

Experience with X-Windows-based applications (such as Imagequery, the
University of California at Berkeley image database) demonstrates the
utility of a client-server topology, but also points to the limitation of
current software for a distributed environment.  For example,
applications like Imagequery can incorporate compression, but current X
implementations do not permit decompression at the end user's
workstation.  Such decompression at the host computer alleviates storage
capacity problems while doing nothing to address problems of
telecommunications bandwidth.

We need to examine the effects on network through-put of moving
multimedia documents around on a network.  We need to examine various
topologies that will help us avoid bottlenecks around servers and
gateways.  Experience with applications such as these raise still broader
questions. How closely is the multimedia document tied to the software
for viewing it?  Can it be accessed and viewed from other applications?
Experience with the MARC format (and more recently with the Z39.50
protocols) shows how useful it can be to store documents in a form in
which they can be accessed by a variety of application software.

Finally, from an intellectual-access standpoint, we need to address the
issue of providing access to these multimedia documents in
interdisciplinary environments.  We need to examine terminology and
indexing strategies that will allow us to provide access to this material
in a cross-disciplinary way.

Ronald LARSEN            Directions in High-Performance Networking for
                         Libraries

The pace at which computing technology has advanced over the past forty
years shows no sign of abating.  Roughly speaking, each five-year period
has yielded an order-of-magnitude improvement in price and performance of
computing equipment.  No fundamental hurdles are likely to prevent this
pace from continuing for at least the next decade.  It is only in the
past five years, though, that computing has become ubiquitous in
libraries, affecting all staff and patrons, directly or indirectly.

During these same five years, communications rates on the Internet, the
principal academic computing network, have grown from 56 kbps to 1.5
Mbps, and the NSFNet backbone is now running 45 Mbps.  Over the next five
years, communication rates on the backbone are expected to exceed 1 Gbps.
Growth in both the population of network users and the volume of network
traffic  has continued to grow geometrically, at rates approaching 15
percent per month.  This flood of capacity and use, likened by some to
"drinking from a firehose,"  creates immense opportunities and challenges
for libraries.  Libraries must anticipate the future implications of this
technology, participate in its development, and deploy it to ensure
access to the world's information resources.

The infrastructure for the information age is being put in place.
Libraries face strategic decisions about their role in the development,
deployment, and use of this infrastructure.  The emerging infrastructure
is much more than computers and communication lines.  It is more than the
ability to compute at a remote site, send electronic mail to a peer
across the country, or move a file from one library to another.  The next
five years will witness substantial development of the information
infrastructure of the network.

In order to provide appropriate leadership, library professionals must
have a fundamental understanding of and appreciation for computer
networking, from local area networks to the National Research and
Education Network (NREN).  This presentation addresses these
fundamentals, and how they relate to libraries today and in the near
future.

Edwin BROWNRIGG               Electronic Library Visions and Realities

The electronic library has been a vision desired by many--and rejected by
some--since Vannevar Bush coined the term memex to describe an automated,
intelligent, personal information system.  Variations on this vision have
included Ted Nelson's Xanadau, Alan Kay's Dynabook, and Lancaster's
"paperless library," with the most recent incarnation being the
"Knowledge Navigator" described by John Scully of Apple.  But the reality
of library service has been less visionary and the leap to the electronic
library has eluded universities, publishers, and information technology
files.

The Memex Research Institute (MemRI), an independent, nonprofit research
and development organization, has created an Electronic Library Program
of shared research and development in order to make the collective vision
more concrete.  The program is working toward the creation of large,
indexed publicly available electronic image collections of published
documents in academic, special, and public libraries.  This strategic
plan is the result of the first stage of the program, which has been an
investigation of the information technologies available to support such
an effort, the economic parameters of electronic service compared to
traditional library operations, and the business and political factors
affecting the shift from print distribution to electronic networked
access.

The strategic plan envisions a combination of publicly searchable access
databases, image (and text) document collections stored on network "file
servers," local and remote network access, and an intellectual property
management-control system.  This combination of technology and
information content is defined in this plan as an E-library or E-library
collection.  Some participating sponsors are already developing projects
based on MemRI's recommended directions.

The E-library strategy projected in this plan is a visionary one that can
enable major changes and improvements in academic, public, and special
library service.  This vision is, though, one that can be realized with
today's technology.  At the same time, it will challenge the political
and social structure within which libraries operate:  in academic
libraries, the traditional emphasis on local collections, extending to
accreditation issues; in public libraries, the potential of electronic
branch and central libraries fully available to the public; and for
special libraries, new opportunities for shared collections and networks.

The environment in which this strategic plan has been developed is, at
the moment, dominated by a sense of library limits.  The continued
expansion and rapid growth of local academic library collections is now
clearly at an end.  Corporate libraries, and even law libraries, are
faced with operating within a difficult economic climate, as well as with
very active competition from commercial information sources.  For
example, public libraries may be seen as a desirable but not critical
municipal service in a time when the budgets of safety and health
agencies are being cut back.

Further, libraries in general have a very high labor-to-cost ratio in
their budgets, and labor costs are still increasing, notwithstanding
automation investments.  It is difficult for libraries to obtain capital,
startup, or seed funding for innovative activities, and those
technology-intensive initiatives that offer the potential of decreased
labor costs can provoke the opposition of library staff.

However, libraries have achieved some considerable successes in the past
two decades by improving both their service and their credibility within
their organizations--and these positive changes have been accomplished
mostly with judicious use of information technologies.  The advances in
computing and information technology have been well-chronicled:  the
continuing precipitous drop in computing costs, the growth of the
Internet and private networks, and the explosive increase in publicly
available information databases.

